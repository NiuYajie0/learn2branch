{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDir = 'results'\n",
    "problems = ['setcover', 'cauctions', 'facilities'] # choices=['setcover', 'cauctions', 'facilities', 'indset']\n",
    "sampling_Strategies = ['uniform5','depthK','depthK2'] # choices: uniform5, depthK, depthK2, depthK3\n",
    "seeds = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'facilities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_df_per_problem(problem):\n",
    "\n",
    "    eval_files = glob.glob(f'{resultDir}/{problem}_*.csv')\n",
    "    eval_file = eval_files[-1]\n",
    "\n",
    "    df = pd.read_csv(eval_file)\n",
    "    df = pd.concat([df[df['type']=='small'], df[df['type']=='medium']])\n",
    "    df = df.astype({'nlps': float, 'nnodes' : float})\n",
    "\n",
    "    df_gcnns = df[df['policy'] != 'internal:relpscost'].copy()\n",
    "\n",
    "    def gmean_1shifted(x):\n",
    "        return stats.mstats.gmean(x + 1) - 1\n",
    "\n",
    "    dfgcnns_gmean = df_gcnns.groupby(['type','sampling_strategy'])[['nnodes', 'stime']].agg(gmean_1shifted)\n",
    "    dfgcnns_mean = df_gcnns.groupby(['type','sampling_strategy'])[['nnodes', 'stime']].mean()\n",
    "\n",
    "    def norm_by_uniform5(dfgcnns_grouped):\n",
    "        df_list = []\n",
    "        for probSize in dfgcnns_grouped.index.levels[0]:\n",
    "            df_list.append(dfgcnns_grouped.loc[probSize] / dfgcnns_grouped.loc[(probSize, 'uniform5')])\n",
    "        return pd.concat(df_list, keys=dfgcnns_grouped.index.levels[0])\n",
    "\n",
    "    dfgcnns_gmean_norm = norm_by_uniform5(dfgcnns_gmean)\n",
    "    dfgcnns_mean_norm = norm_by_uniform5(dfgcnns_mean)\n",
    "\n",
    "    dfgcnns_std_norm_perInstance = df_gcnns.groupby(['type','sampling_strategy','instance']).std() / df_gcnns.groupby(['type','sampling_strategy','instance']).mean()\n",
    "    dfgcnns_std_norm = dfgcnns_std_norm_perInstance.groupby(['type','sampling_strategy'])[['nnodes','stime']].mean()\n",
    "\n",
    "    ttest_res = pd.DataFrame(index=dfgcnns_mean_norm.index, columns=pd.MultiIndex.from_product((['nnodes', 'stime'], ['t_stats', 'p_value'])))\n",
    "    for metric in ['nnodes', 'stime']:\n",
    "        for probSize in dfgcnns_mean_norm.index.levels[0]: # medium, small\n",
    "            mean2 = 1\n",
    "            std2 = dfgcnns_std_norm.at[(probSize,'uniform5'),metric]\n",
    "            for sampling_strategy in dfgcnns_mean_norm.index.levels[1]: # depthK, depthK2, uniform5\n",
    "                mean1 = dfgcnns_mean_norm.at[(probSize,sampling_strategy),metric]\n",
    "                std1_norm = dfgcnns_std_norm.at[(probSize,sampling_strategy),metric]\n",
    "                std1 = std1_norm * mean1\n",
    "                t_stats, p_value = stats.ttest_ind_from_stats(mean1, std1, 100, mean2, std2, 100)\n",
    "                ttest_res.loc[(probSize,sampling_strategy),(metric,)] = [t_stats, p_value]\n",
    "\n",
    "    def get_winner_indices(x):\n",
    "        return x.idxmin()\n",
    "\n",
    "    winner_idx = df_gcnns.groupby(['type','instance','seed'])['stime'].agg(pd.Series.idxmin)\n",
    "    df_gcnns['wins'] = 0\n",
    "    df_gcnns.loc[winner_idx,'wins'] = 1\n",
    "    dfgcnns_wins = df_gcnns.groupby(['type', 'sampling_strategy'])['wins'].sum()\n",
    "\n",
    "    output_idx = pd.MultiIndex.from_product((['small', 'medium'], sampling_Strategies), names=['type', 'sampling_strategy'])\n",
    "\n",
    "    output_df_mean = dfgcnns_gmean_norm.reindex(output_idx)\n",
    "    output_df_std = dfgcnns_std_norm.reindex(output_idx)\n",
    "    output_df_wins = dfgcnns_wins.reindex(output_idx)\n",
    "    output_df_ttest = ttest_res.reindex(output_idx)\n",
    "\n",
    "    out_df1 = pd.DataFrame(index=output_idx, columns=pd.Index(['nnodes', 'stime', 'wins', 't-stats (p-val)'], name='metrics'))\n",
    "\n",
    "    for col_name in ['nnodes', 'stime']:\n",
    "        out_df1[col_name] = [\"%.4fr ± %.2f\" % (m, s*100) + \"%\" for (m, s) in zip(output_df_mean[col_name], output_df_std[col_name])]\n",
    "    out_df1['wins'] = output_df_wins\n",
    "    out_df1['t-stats (p-val)'] = [\"%.2f (%.4f)\" % (t, p) for (t, p) in zip(output_df_ttest[('stime','t_stats')], output_df_ttest[('stime','p_value')])]\n",
    "    return out_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_summaries = {problem : get_summary_df_per_problem(problem) for problem in problems}\n",
    "# df_facilities = get_summary_df_per_problem('facilities')\n",
    "# df_setcover = get_summary_df_per_problem('setcover')\n",
    "# df_cauctions = get_summary_df_per_problem('cauctions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs_dict = {}\n",
    "for problem, prob_df in df_prob_summaries.items():\n",
    "    moved_keys = prob_df.index.get_level_values('type').unique()\n",
    "    df_probs_dict[problem] =  pd.concat([prob_df.loc[probSize] for probSize in moved_keys], axis=1, keys=moved_keys)\n",
    "df_summaries_allProbs = pd.concat(df_probs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = f\"{resultDir}/eval_allProbs\"\n",
    "# df_summaries_allProbs.to_csv(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>nnodes</th>\n",
       "      <th>stime</th>\n",
       "      <th>wins</th>\n",
       "      <th>t-stats (p-val)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>sampling_strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">small</th>\n",
       "      <th>uniform5</th>\n",
       "      <td>1.0000r ± 22.13%</td>\n",
       "      <td>1.0000r ± 15.13%</td>\n",
       "      <td>25</td>\n",
       "      <td>0.00(1.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depthK</th>\n",
       "      <td>0.9955r ± 23.31%</td>\n",
       "      <td>0.9842r ± 14.66%</td>\n",
       "      <td>39</td>\n",
       "      <td>-1.00(0.3209)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depthK2</th>\n",
       "      <td>1.0032r ± 23.29%</td>\n",
       "      <td>0.9950r ± 14.72%</td>\n",
       "      <td>36</td>\n",
       "      <td>0.17(0.8618)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">medium</th>\n",
       "      <th>uniform5</th>\n",
       "      <td>1.0000r ± 14.78%</td>\n",
       "      <td>1.0000r ± 15.13%</td>\n",
       "      <td>33</td>\n",
       "      <td>0.00(1.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depthK</th>\n",
       "      <td>1.0070r ± 16.22%</td>\n",
       "      <td>1.0043r ± 14.29%</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.26(0.7949)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depthK2</th>\n",
       "      <td>1.0375r ± 16.26%</td>\n",
       "      <td>1.0090r ± 15.23%</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.89(0.3725)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metrics                             nnodes             stime  wins  \\\n",
       "type   sampling_strategy                                             \n",
       "small  uniform5           1.0000r ± 22.13%  1.0000r ± 15.13%    25   \n",
       "       depthK             0.9955r ± 23.31%  0.9842r ± 14.66%    39   \n",
       "       depthK2            1.0032r ± 23.29%  0.9950r ± 14.72%    36   \n",
       "medium uniform5           1.0000r ± 14.78%  1.0000r ± 15.13%    33   \n",
       "       depthK             1.0070r ± 16.22%  1.0043r ± 14.29%    25   \n",
       "       depthK2            1.0375r ± 16.26%  1.0090r ± 15.23%    42   \n",
       "\n",
       "metrics                  t-stats (p-val)  \n",
       "type   sampling_strategy                  \n",
       "small  uniform5             0.00(1.0000)  \n",
       "       depthK              -1.00(0.3209)  \n",
       "       depthK2              0.17(0.8618)  \n",
       "medium uniform5             0.00(1.0000)  \n",
       "       depthK              -0.26(0.7949)  \n",
       "       depthK2             -0.89(0.3725)  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob_summaries['facilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_summaries['facilities'].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summaries_allProbs.to_excel(output_filepath+\".xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f\"{resultDir}/eval_allProbs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summaries_allProbs.to_excel(output_filepath+\".xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel(output_filepath+\".xls\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2197b5b8e9b471505d2ded00a61d2651dac29e8904a63bed27e0708da5f1381"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn2branch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}